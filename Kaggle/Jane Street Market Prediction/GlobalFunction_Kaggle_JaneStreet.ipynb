{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of this notebook:\n",
    "1. Explain Notebook\n",
    "2. Serve as stepping stone to allow function to be reproduced across TS Pred Domains\n",
    "\n",
    "### Competition Explanation\n",
    "1. Leaderboard score: 6476\n",
    "2. Notebook Score: 9766, which served as baseline and building block to notebook of score: 11,480\n",
    "3. Notebook Credit: https://www.kaggle.com/code/tarlannazarov/own-jane-street-with-keras-nn/notebook\n",
    "\n",
    "#### From : 1_MLP Model_Part 3 - Global Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0-dev20210806\n",
      "2.6.0\n",
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "# Print Tensorflow, Keras, Numpy version to make version clear to prevent dependecy issues\n",
    "import tensorflow\n",
    "import keras\n",
    "import numpy \n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import choices\n",
    "\n",
    "class Kaggle_custom():\n",
    "    def __init__(self, n_jobs=-1, verbose=0):\n",
    "        self.n_jobs = n_jobs # -1: all CPUs are used\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def JaneStreet_MLP_model_1(self, df, date, target_list, features_list,\n",
    "                            \n",
    "                            train_test_split_size,\n",
    "                            fillna_type,\n",
    "                            \n",
    "                            batch_size,\n",
    "                            hidden_units,\n",
    "                            dropout_rates,\n",
    "                            label_smoothing,\n",
    "                            learning_rate,\n",
    "                            epochs,                            \n",
    "                            ):\n",
    "        \n",
    "        '''\n",
    "        format:\n",
    "        :param Parameter: [type]: {Example or Explanation}\n",
    "        \n",
    "        :param df: [pandas DataFrame]: {DataFrame}\n",
    "        :param date: Not Required, for future input reference\n",
    "        :param target_list: [List] : {target(s) column list}\n",
    "        :param features_list: [List] : {features column list}\n",
    "\n",
    "        :param batch_size: [int] : {5000}\n",
    "        :param hidden_units: [List] : {[150, 150, 150]}\n",
    "        :param dropout_rates: [List] : {[0.2, 0.2, 0.2, 0.2]}\n",
    "        :param label_smoothing: [exponential notation] : {1e-2}\n",
    "        :param learning_rate: [exponential notation] : {1e-3}\n",
    "        :param epochs: [int] : {2000}   \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        print('[Warning] This is a MULTI VARIATE Time Series Prediction')\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        #Param PreProcessing\n",
    "        train, test = train_test_split(df, test_size=train_test_split_size, shuffle=False)\n",
    "        features = features_list\n",
    "        \n",
    "        if fillna_type == 'mean':\n",
    "            train.fillna(train.mean(),inplace=True)\n",
    "        else:\n",
    "            #input custom lambda function or fill_value function\n",
    "            fill_value = train.fillna(fill_value, inplace=True)\n",
    "\n",
    "        train['action'] = ((train['resp'].values) > 0).astype(int)\n",
    "\n",
    "#         f_mean = np.mean(train[features[1:]].values,axis=0) #Original\n",
    "        f_mean = np.mean(train[features].values,axis=0) # preferred\n",
    "\n",
    "        X_train = train.loc[:, train.columns.str.contains('feature')]\n",
    "        y_train = np.stack([(train[c] > 0).astype('int') for c in target_list]).T\n",
    "\n",
    "        def create_mlp(\n",
    "            num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "        ):\n",
    "\n",
    "            inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "            x = tf.keras.layers.BatchNormalization()(inp)\n",
    "            x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "            for i in range(len(hidden_units)):\n",
    "                x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "                x = tf.keras.layers.BatchNormalization()(x)\n",
    "                x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "                x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "            x = tf.keras.layers.Dense(num_labels)(x)\n",
    "            out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "            model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "                metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "            )\n",
    "\n",
    "            return model\n",
    "\n",
    "        #Create Model\n",
    "        clf = create_mlp(len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate)\n",
    "        clf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)#epochs=200\n",
    "\n",
    "        models = []\n",
    "        models.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.049202</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.015541</td>\n",
       "      <td>0.024346</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.541864</td>\n",
       "      <td>0.457145</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.396750</td>\n",
       "      <td>-1.740766</td>\n",
       "      <td>0.984241</td>\n",
       "      <td>1.055600</td>\n",
       "      <td>-0.079467</td>\n",
       "      <td>-2.650392</td>\n",
       "      <td>-1.981605</td>\n",
       "      <td>1.783659</td>\n",
       "      <td>2.866631</td>\n",
       "      <td>87701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.180770</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.435043</td>\n",
       "      <td>-0.801688</td>\n",
       "      <td>...</td>\n",
       "      <td>2.363126</td>\n",
       "      <td>3.088412</td>\n",
       "      <td>-0.680165</td>\n",
       "      <td>-1.452415</td>\n",
       "      <td>-0.482993</td>\n",
       "      <td>0.021540</td>\n",
       "      <td>0.460060</td>\n",
       "      <td>3.930716</td>\n",
       "      <td>-1.233066</td>\n",
       "      <td>131161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.807942</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000691</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.615491</td>\n",
       "      <td>3.070859</td>\n",
       "      <td>...</td>\n",
       "      <td>1.650663</td>\n",
       "      <td>4.536699</td>\n",
       "      <td>-2.317647</td>\n",
       "      <td>0.789400</td>\n",
       "      <td>0.455739</td>\n",
       "      <td>1.509873</td>\n",
       "      <td>-0.890321</td>\n",
       "      <td>-0.652885</td>\n",
       "      <td>1.805953</td>\n",
       "      <td>1964156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>-0.002512</td>\n",
       "      <td>-0.014387</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>1.501052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743715</td>\n",
       "      <td>0.153879</td>\n",
       "      <td>0.180128</td>\n",
       "      <td>-0.653379</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>-3.604416</td>\n",
       "      <td>-1.060510</td>\n",
       "      <td>4.761398</td>\n",
       "      <td>2.454472</td>\n",
       "      <td>1360299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.217674</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-0.515529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277117</td>\n",
       "      <td>1.552482</td>\n",
       "      <td>-0.348023</td>\n",
       "      <td>-0.944887</td>\n",
       "      <td>3.885566</td>\n",
       "      <td>1.968201</td>\n",
       "      <td>-1.015298</td>\n",
       "      <td>0.642338</td>\n",
       "      <td>0.242971</td>\n",
       "      <td>1024723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194617</th>\n",
       "      <td>41</td>\n",
       "      <td>9.499657</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>-0.003893</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>-1.390194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.667969</td>\n",
       "      <td>1.654635</td>\n",
       "      <td>-3.354002</td>\n",
       "      <td>-1.561084</td>\n",
       "      <td>-0.021235</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.578562</td>\n",
       "      <td>2.351930</td>\n",
       "      <td>-1.043938</td>\n",
       "      <td>2245831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194618</th>\n",
       "      <td>41</td>\n",
       "      <td>0.880071</td>\n",
       "      <td>-0.009220</td>\n",
       "      <td>-0.010878</td>\n",
       "      <td>-0.016373</td>\n",
       "      <td>-0.005701</td>\n",
       "      <td>-0.004407</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.033749</td>\n",
       "      <td>-1.119539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142546</td>\n",
       "      <td>-0.441910</td>\n",
       "      <td>2.025904</td>\n",
       "      <td>1.111816</td>\n",
       "      <td>-0.007807</td>\n",
       "      <td>-0.383317</td>\n",
       "      <td>-0.112840</td>\n",
       "      <td>-0.702947</td>\n",
       "      <td>-0.997980</td>\n",
       "      <td>1805522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194619</th>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>1</td>\n",
       "      <td>4.933404</td>\n",
       "      <td>0.358317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265527</td>\n",
       "      <td>0.414859</td>\n",
       "      <td>-0.555553</td>\n",
       "      <td>1.416021</td>\n",
       "      <td>0.502948</td>\n",
       "      <td>-1.193979</td>\n",
       "      <td>-1.451042</td>\n",
       "      <td>1.141000</td>\n",
       "      <td>-1.156276</td>\n",
       "      <td>1742984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194620</th>\n",
       "      <td>41</td>\n",
       "      <td>0.078104</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>1</td>\n",
       "      <td>2.024954</td>\n",
       "      <td>-0.685283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665552</td>\n",
       "      <td>0.218148</td>\n",
       "      <td>0.648862</td>\n",
       "      <td>-1.365715</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>0.601280</td>\n",
       "      <td>3.224246</td>\n",
       "      <td>-0.650631</td>\n",
       "      <td>-1.370604</td>\n",
       "      <td>887604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194621</th>\n",
       "      <td>41</td>\n",
       "      <td>1.821867</td>\n",
       "      <td>-0.001364</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.003310</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1</td>\n",
       "      <td>4.862565</td>\n",
       "      <td>5.540202</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.670763</td>\n",
       "      <td>0.153567</td>\n",
       "      <td>-2.253743</td>\n",
       "      <td>1.257677</td>\n",
       "      <td>-0.393732</td>\n",
       "      <td>-1.254929</td>\n",
       "      <td>-1.516557</td>\n",
       "      <td>-0.194138</td>\n",
       "      <td>5.912747</td>\n",
       "      <td>1444418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194622 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0          0  0.049202  0.002514  0.004059  0.015541  0.024346  0.017530   \n",
       "1          0  0.180770 -0.000232  0.000292  0.001638  0.002670  0.000906   \n",
       "2          0  0.807942  0.000639  0.001136  0.002258  0.000157 -0.000691   \n",
       "3          0  0.000000  0.003162  0.002086 -0.002512 -0.014387 -0.008368   \n",
       "4          0  0.217674 -0.000255 -0.000340  0.001560  0.004779  0.003217   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "194617    41  9.499657 -0.000010 -0.000433 -0.002241 -0.003893 -0.000241   \n",
       "194618    41  0.880071 -0.009220 -0.010878 -0.016373 -0.005701 -0.004407   \n",
       "194619    41  0.000000  0.005172  0.004708  0.009887  0.013415  0.008206   \n",
       "194620    41  0.078104 -0.001270 -0.001045  0.006422  0.016154  0.010319   \n",
       "194621    41  1.821867 -0.001364 -0.000164 -0.003310 -0.000708  0.000053   \n",
       "\n",
       "        feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0               1  -2.541864   0.457145  ...    -1.396750    -1.740766   \n",
       "1               1   1.435043  -0.801688  ...     2.363126     3.088412   \n",
       "2               1  -1.615491   3.070859  ...     1.650663     4.536699   \n",
       "3              -1  -3.172026   1.501052  ...    -0.743715     0.153879   \n",
       "4              -1  -3.172026  -0.515529  ...    -0.277117     1.552482   \n",
       "...           ...        ...        ...  ...          ...          ...   \n",
       "194617         -1   2.338139  -1.390194  ...    -0.667969     1.654635   \n",
       "194618         -1   3.033749  -1.119539  ...    -0.142546    -0.441910   \n",
       "194619          1   4.933404   0.358317  ...     0.265527     0.414859   \n",
       "194620          1   2.024954  -0.685283  ...     0.665552     0.218148   \n",
       "194621          1   4.862565   5.540202  ...    -1.670763     0.153567   \n",
       "\n",
       "        feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0          0.984241     1.055600    -0.079467    -2.650392    -1.981605   \n",
       "1         -0.680165    -1.452415    -0.482993     0.021540     0.460060   \n",
       "2         -2.317647     0.789400     0.455739     1.509873    -0.890321   \n",
       "3          0.180128    -0.653379     0.809250    -3.604416    -1.060510   \n",
       "4         -0.348023    -0.944887     3.885566     1.968201    -1.015298   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "194617    -3.354002    -1.561084    -0.021235     0.304516     0.578562   \n",
       "194618     2.025904     1.111816    -0.007807    -0.383317    -0.112840   \n",
       "194619    -0.555553     1.416021     0.502948    -1.193979    -1.451042   \n",
       "194620     0.648862    -1.365715     0.255495     0.601280     3.224246   \n",
       "194621    -2.253743     1.257677    -0.393732    -1.254929    -1.516557   \n",
       "\n",
       "        feature_128  feature_129    ts_id  \n",
       "0          1.783659     2.866631    87701  \n",
       "1          3.930716    -1.233066   131161  \n",
       "2         -0.652885     1.805953  1964156  \n",
       "3          4.761398     2.454472  1360299  \n",
       "4          0.642338     0.242971  1024723  \n",
       "...             ...          ...      ...  \n",
       "194617     2.351930    -1.043938  2245831  \n",
       "194618    -0.702947    -0.997980  1805522  \n",
       "194619     1.141000    -1.156276  1742984  \n",
       "194620    -0.650631    -1.370604   887604  \n",
       "194621    -0.194138     5.912747  1444418  \n",
       "\n",
       "[194622 rows x 138 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../../git_datasets/Jane Street Data/Splitted_Data/JaneStreet_Part0.csv',index_col = 0)\n",
    "features_list = [c for c in df.columns if \"feature\" in c]\n",
    "date = 'date' \n",
    "target_list = 'resp'\n",
    "feature = ['feature1','feature2'] \n",
    "target_list = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "train_test_split_size = 0.2\n",
    "fillna_type = 'mean'      #Choose fill Type 1 \n",
    "df\n",
    "\n",
    "# fill_value = train.mean() #Choose fill Type 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe Input Params: [df, date, target_list, features_list,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.049202</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.015541</td>\n",
       "      <td>0.024346</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.541864</td>\n",
       "      <td>0.457145</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.396750</td>\n",
       "      <td>-1.740766</td>\n",
       "      <td>0.984241</td>\n",
       "      <td>1.055600</td>\n",
       "      <td>-0.079467</td>\n",
       "      <td>-2.650392</td>\n",
       "      <td>-1.981605</td>\n",
       "      <td>1.783659</td>\n",
       "      <td>2.866631</td>\n",
       "      <td>87701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.180770</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.435043</td>\n",
       "      <td>-0.801688</td>\n",
       "      <td>...</td>\n",
       "      <td>2.363126</td>\n",
       "      <td>3.088412</td>\n",
       "      <td>-0.680165</td>\n",
       "      <td>-1.452415</td>\n",
       "      <td>-0.482993</td>\n",
       "      <td>0.021540</td>\n",
       "      <td>0.460060</td>\n",
       "      <td>3.930716</td>\n",
       "      <td>-1.233066</td>\n",
       "      <td>131161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.807942</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000691</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.615491</td>\n",
       "      <td>3.070859</td>\n",
       "      <td>...</td>\n",
       "      <td>1.650663</td>\n",
       "      <td>4.536699</td>\n",
       "      <td>-2.317647</td>\n",
       "      <td>0.789400</td>\n",
       "      <td>0.455739</td>\n",
       "      <td>1.509873</td>\n",
       "      <td>-0.890321</td>\n",
       "      <td>-0.652885</td>\n",
       "      <td>1.805953</td>\n",
       "      <td>1964156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>-0.002512</td>\n",
       "      <td>-0.014387</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>1.501052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743715</td>\n",
       "      <td>0.153879</td>\n",
       "      <td>0.180128</td>\n",
       "      <td>-0.653379</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>-3.604416</td>\n",
       "      <td>-1.060510</td>\n",
       "      <td>4.761398</td>\n",
       "      <td>2.454472</td>\n",
       "      <td>1360299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.217674</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-0.515529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277117</td>\n",
       "      <td>1.552482</td>\n",
       "      <td>-0.348023</td>\n",
       "      <td>-0.944887</td>\n",
       "      <td>3.885566</td>\n",
       "      <td>1.968201</td>\n",
       "      <td>-1.015298</td>\n",
       "      <td>0.642338</td>\n",
       "      <td>0.242971</td>\n",
       "      <td>1024723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194617</th>\n",
       "      <td>41</td>\n",
       "      <td>9.499657</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>-0.003893</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>-1.390194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.667969</td>\n",
       "      <td>1.654635</td>\n",
       "      <td>-3.354002</td>\n",
       "      <td>-1.561084</td>\n",
       "      <td>-0.021235</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.578562</td>\n",
       "      <td>2.351930</td>\n",
       "      <td>-1.043938</td>\n",
       "      <td>2245831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194618</th>\n",
       "      <td>41</td>\n",
       "      <td>0.880071</td>\n",
       "      <td>-0.009220</td>\n",
       "      <td>-0.010878</td>\n",
       "      <td>-0.016373</td>\n",
       "      <td>-0.005701</td>\n",
       "      <td>-0.004407</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.033749</td>\n",
       "      <td>-1.119539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142546</td>\n",
       "      <td>-0.441910</td>\n",
       "      <td>2.025904</td>\n",
       "      <td>1.111816</td>\n",
       "      <td>-0.007807</td>\n",
       "      <td>-0.383317</td>\n",
       "      <td>-0.112840</td>\n",
       "      <td>-0.702947</td>\n",
       "      <td>-0.997980</td>\n",
       "      <td>1805522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194619</th>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>1</td>\n",
       "      <td>4.933404</td>\n",
       "      <td>0.358317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265527</td>\n",
       "      <td>0.414859</td>\n",
       "      <td>-0.555553</td>\n",
       "      <td>1.416021</td>\n",
       "      <td>0.502948</td>\n",
       "      <td>-1.193979</td>\n",
       "      <td>-1.451042</td>\n",
       "      <td>1.141000</td>\n",
       "      <td>-1.156276</td>\n",
       "      <td>1742984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194620</th>\n",
       "      <td>41</td>\n",
       "      <td>0.078104</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>1</td>\n",
       "      <td>2.024954</td>\n",
       "      <td>-0.685283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665552</td>\n",
       "      <td>0.218148</td>\n",
       "      <td>0.648862</td>\n",
       "      <td>-1.365715</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>0.601280</td>\n",
       "      <td>3.224246</td>\n",
       "      <td>-0.650631</td>\n",
       "      <td>-1.370604</td>\n",
       "      <td>887604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194621</th>\n",
       "      <td>41</td>\n",
       "      <td>1.821867</td>\n",
       "      <td>-0.001364</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.003310</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1</td>\n",
       "      <td>4.862565</td>\n",
       "      <td>5.540202</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.670763</td>\n",
       "      <td>0.153567</td>\n",
       "      <td>-2.253743</td>\n",
       "      <td>1.257677</td>\n",
       "      <td>-0.393732</td>\n",
       "      <td>-1.254929</td>\n",
       "      <td>-1.516557</td>\n",
       "      <td>-0.194138</td>\n",
       "      <td>5.912747</td>\n",
       "      <td>1444418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194622 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0          0  0.049202  0.002514  0.004059  0.015541  0.024346  0.017530   \n",
       "1          0  0.180770 -0.000232  0.000292  0.001638  0.002670  0.000906   \n",
       "2          0  0.807942  0.000639  0.001136  0.002258  0.000157 -0.000691   \n",
       "3          0  0.000000  0.003162  0.002086 -0.002512 -0.014387 -0.008368   \n",
       "4          0  0.217674 -0.000255 -0.000340  0.001560  0.004779  0.003217   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "194617    41  9.499657 -0.000010 -0.000433 -0.002241 -0.003893 -0.000241   \n",
       "194618    41  0.880071 -0.009220 -0.010878 -0.016373 -0.005701 -0.004407   \n",
       "194619    41  0.000000  0.005172  0.004708  0.009887  0.013415  0.008206   \n",
       "194620    41  0.078104 -0.001270 -0.001045  0.006422  0.016154  0.010319   \n",
       "194621    41  1.821867 -0.001364 -0.000164 -0.003310 -0.000708  0.000053   \n",
       "\n",
       "        feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0               1  -2.541864   0.457145  ...    -1.396750    -1.740766   \n",
       "1               1   1.435043  -0.801688  ...     2.363126     3.088412   \n",
       "2               1  -1.615491   3.070859  ...     1.650663     4.536699   \n",
       "3              -1  -3.172026   1.501052  ...    -0.743715     0.153879   \n",
       "4              -1  -3.172026  -0.515529  ...    -0.277117     1.552482   \n",
       "...           ...        ...        ...  ...          ...          ...   \n",
       "194617         -1   2.338139  -1.390194  ...    -0.667969     1.654635   \n",
       "194618         -1   3.033749  -1.119539  ...    -0.142546    -0.441910   \n",
       "194619          1   4.933404   0.358317  ...     0.265527     0.414859   \n",
       "194620          1   2.024954  -0.685283  ...     0.665552     0.218148   \n",
       "194621          1   4.862565   5.540202  ...    -1.670763     0.153567   \n",
       "\n",
       "        feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0          0.984241     1.055600    -0.079467    -2.650392    -1.981605   \n",
       "1         -0.680165    -1.452415    -0.482993     0.021540     0.460060   \n",
       "2         -2.317647     0.789400     0.455739     1.509873    -0.890321   \n",
       "3          0.180128    -0.653379     0.809250    -3.604416    -1.060510   \n",
       "4         -0.348023    -0.944887     3.885566     1.968201    -1.015298   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "194617    -3.354002    -1.561084    -0.021235     0.304516     0.578562   \n",
       "194618     2.025904     1.111816    -0.007807    -0.383317    -0.112840   \n",
       "194619    -0.555553     1.416021     0.502948    -1.193979    -1.451042   \n",
       "194620     0.648862    -1.365715     0.255495     0.601280     3.224246   \n",
       "194621    -2.253743     1.257677    -0.393732    -1.254929    -1.516557   \n",
       "\n",
       "        feature_128  feature_129    ts_id  \n",
       "0          1.783659     2.866631    87701  \n",
       "1          3.930716    -1.233066   131161  \n",
       "2         -0.652885     1.805953  1964156  \n",
       "3          4.761398     2.454472  1360299  \n",
       "4          0.642338     0.242971  1024723  \n",
       "...             ...          ...      ...  \n",
       "194617     2.351930    -1.043938  2245831  \n",
       "194618    -0.702947    -0.997980  1805522  \n",
       "194619     1.141000    -1.156276  1742984  \n",
       "194620    -0.650631    -1.370604   887604  \n",
       "194621    -0.194138     5.912747  1444418  \n",
       "\n",
       "[194622 rows x 138 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_25',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_28',\n",
       " 'feature_29',\n",
       " 'feature_30',\n",
       " 'feature_31',\n",
       " 'feature_32',\n",
       " 'feature_33',\n",
       " 'feature_34',\n",
       " 'feature_35',\n",
       " 'feature_36',\n",
       " 'feature_37',\n",
       " 'feature_38',\n",
       " 'feature_39',\n",
       " 'feature_40',\n",
       " 'feature_41',\n",
       " 'feature_42',\n",
       " 'feature_43',\n",
       " 'feature_44',\n",
       " 'feature_45',\n",
       " 'feature_46',\n",
       " 'feature_47',\n",
       " 'feature_48',\n",
       " 'feature_49',\n",
       " 'feature_50',\n",
       " 'feature_51',\n",
       " 'feature_52',\n",
       " 'feature_53',\n",
       " 'feature_54',\n",
       " 'feature_55',\n",
       " 'feature_56',\n",
       " 'feature_57',\n",
       " 'feature_58',\n",
       " 'feature_59',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_62',\n",
       " 'feature_63',\n",
       " 'feature_64',\n",
       " 'feature_65',\n",
       " 'feature_66',\n",
       " 'feature_67',\n",
       " 'feature_68',\n",
       " 'feature_69',\n",
       " 'feature_70',\n",
       " 'feature_71',\n",
       " 'feature_72',\n",
       " 'feature_73',\n",
       " 'feature_74',\n",
       " 'feature_75',\n",
       " 'feature_76',\n",
       " 'feature_77',\n",
       " 'feature_78',\n",
       " 'feature_79',\n",
       " 'feature_80',\n",
       " 'feature_81',\n",
       " 'feature_82',\n",
       " 'feature_83',\n",
       " 'feature_84',\n",
       " 'feature_85',\n",
       " 'feature_86',\n",
       " 'feature_87',\n",
       " 'feature_88',\n",
       " 'feature_89',\n",
       " 'feature_90',\n",
       " 'feature_91',\n",
       " 'feature_92',\n",
       " 'feature_93',\n",
       " 'feature_94',\n",
       " 'feature_95',\n",
       " 'feature_96',\n",
       " 'feature_97',\n",
       " 'feature_98',\n",
       " 'feature_99',\n",
       " 'feature_100',\n",
       " 'feature_101',\n",
       " 'feature_102',\n",
       " 'feature_103',\n",
       " 'feature_104',\n",
       " 'feature_105',\n",
       " 'feature_106',\n",
       " 'feature_107',\n",
       " 'feature_108',\n",
       " 'feature_109',\n",
       " 'feature_110',\n",
       " 'feature_111',\n",
       " 'feature_112',\n",
       " 'feature_113',\n",
       " 'feature_114',\n",
       " 'feature_115',\n",
       " 'feature_116',\n",
       " 'feature_117',\n",
       " 'feature_118',\n",
       " 'feature_119',\n",
       " 'feature_120',\n",
       " 'feature_121',\n",
       " 'feature_122',\n",
       " 'feature_123',\n",
       " 'feature_124',\n",
       " 'feature_125',\n",
       " 'feature_126',\n",
       " 'feature_127',\n",
       " 'feature_128',\n",
       " 'feature_129']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] This is a MULTI VARIATE Time Series Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\malco\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\series.py:4536: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "c:\\users\\malco\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.7341 - AUC: 0.5000\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.7107 - AUC: 0.5005\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('./Jane Street Data/Splitted_Data/JaneStreet_Part0.csv',index_col = 0)\n",
    "# features_list = [c for c in df.columns if \"feature\" in c]\n",
    "# date = 'date' \n",
    "# target_list = 'resp'\n",
    "# feature = ['feature1','feature2'] \n",
    "# target_list = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "# train_test_split_size = 0.2\n",
    "# fillna_type = 'mean'      #Choose fill Type 1 \n",
    "# # fill_value = train.mean() #Choose fill Type 2\n",
    "\n",
    "# Kaggle_custom().JaneStreet_MLP_model_1(df, date, target_list, features_list,\n",
    "                                       \n",
    "#                                        train_test_split_size=0.2,\n",
    "#                                        fillna_type=fillna_type,\n",
    "#                                         batch_size = 5000,\n",
    "#                                         hidden_units = [150, 150, 150],\n",
    "#                                         dropout_rates = [0.2, 0.2, 0.2, 0.2],\n",
    "#                                         label_smoothing = 1e-2,\n",
    "#                                         learning_rate = 1e-3,\n",
    "#                                         epochs=2#2000\n",
    "#                                     )        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
