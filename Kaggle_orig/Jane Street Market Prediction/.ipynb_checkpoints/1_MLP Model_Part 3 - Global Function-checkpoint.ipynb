{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of this notebook:\n",
    "1. Explain Notebook\n",
    "2. Serve as stepping stone to allow function to be reproduced across TS Pred Domains\n",
    "\n",
    "### Competition Explanation\n",
    "1. Leaderboard score: 6476\n",
    "2. Notebook Score: 9766, which served as baseline and building block to notebook of score: 11,480\n",
    "3. Notebook Credit: https://www.kaggle.com/code/tarlannazarov/own-jane-street-with-keras-nn/notebook\n",
    "\n",
    "#### From : 1_MLP Model_Part 3 - Global Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0-dev20210806\n",
      "2.6.0\n",
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "# Print Tensorflow, Keras, Numpy version to make version clear to prevent dependecy issues\n",
    "import tensorflow\n",
    "import keras\n",
    "import numpy \n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import choices\n",
    "\n",
    "class Kaggle_custom():\n",
    "    def __init__(self, n_jobs=-1, verbose=0):\n",
    "        self.n_jobs = n_jobs # -1: all CPUs are used\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def JaneStreet_MLP_model_1(self, df, date, target_list, features_list,\n",
    "                            \n",
    "                            train_test_split_size,\n",
    "                            fillna_type,\n",
    "                            \n",
    "                            batch_size,\n",
    "                            hidden_units,\n",
    "                            dropout_rates,\n",
    "                            label_smoothing,\n",
    "                            learning_rate,\n",
    "                            epochs,                            \n",
    "                            ):\n",
    "        \n",
    "        '''\n",
    "        format:\n",
    "        :param Parameter: [type]: {Example or Explanation}\n",
    "        \n",
    "        :param df: [pandas DataFrame]: {DataFrame}\n",
    "        :param date: Not Required, for future input reference\n",
    "        :param target_list: [List] : {target(s) column list}\n",
    "        :param features_list: [List] : {features column list}\n",
    "\n",
    "        :param batch_size: [int] : {5000}\n",
    "        :param hidden_units: [List] : {[150, 150, 150]}\n",
    "        :param dropout_rates: [List] : {[0.2, 0.2, 0.2, 0.2]}\n",
    "        :param label_smoothing: [exponential notation] : {1e-2}\n",
    "        :param learning_rate: [exponential notation] : {1e-3}\n",
    "        :param epochs: [int] : {2000}   \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        print('[Warning] This is a MULTI VARIATE Time Series Prediction')\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        #Param PreProcessing\n",
    "        train, test = train_test_split(df, test_size=train_test_split_size, shuffle=False)\n",
    "        features = features_list\n",
    "        \n",
    "        if fillna_type == 'mean':\n",
    "            train.fillna(train.mean(),inplace=True)\n",
    "        else:\n",
    "            #input custom lambda function or fill_value function\n",
    "            fill_value = train.fillna(fill_value, inplace=True)\n",
    "\n",
    "        train['action'] = ((train['resp'].values) > 0).astype(int)\n",
    "\n",
    "#         f_mean = np.mean(train[features[1:]].values,axis=0) #Original\n",
    "        f_mean = np.mean(train[features].values,axis=0) # preferred\n",
    "\n",
    "        X_train = train.loc[:, train.columns.str.contains('feature')]\n",
    "        y_train = np.stack([(train[c] > 0).astype('int') for c in target_list]).T\n",
    "\n",
    "        def create_mlp(\n",
    "            num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "        ):\n",
    "\n",
    "            inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "            x = tf.keras.layers.BatchNormalization()(inp)\n",
    "            x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "            for i in range(len(hidden_units)):\n",
    "                x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "                x = tf.keras.layers.BatchNormalization()(x)\n",
    "                x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "                x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "            x = tf.keras.layers.Dense(num_labels)(x)\n",
    "            out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "            model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "                metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "            )\n",
    "\n",
    "            return model\n",
    "\n",
    "        #Create Model\n",
    "        clf = create_mlp(len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate)\n",
    "        clf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)#epochs=200\n",
    "\n",
    "        models = []\n",
    "        models.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] This is a MULTI VARIATE Time Series Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\malco\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\series.py:4536: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "c:\\users\\malco\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.7341 - AUC: 0.5000\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.7107 - AUC: 0.5005\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('./Jane Street Data/Splitted_Data/JaneStreet_Part0.csv',index_col = 0)\n",
    "# features_list = [c for c in df.columns if \"feature\" in c]\n",
    "# date = 'date' \n",
    "# target_list = 'resp'\n",
    "# feature = ['feature1','feature2'] \n",
    "# target_list = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "# train_test_split_size = 0.2\n",
    "# fillna_type = 'mean'      #Choose fill Type 1 \n",
    "# # fill_value = train.mean() #Choose fill Type 2\n",
    "\n",
    "# Kaggle_custom().JaneStreet_MLP_model_1(df, date, target_list, features_list,\n",
    "                                       \n",
    "#                                        train_test_split_size=0.2,\n",
    "#                                        fillna_type=fillna_type,\n",
    "#                                         batch_size = 5000,\n",
    "#                                         hidden_units = [150, 150, 150],\n",
    "#                                         dropout_rates = [0.2, 0.2, 0.2, 0.2],\n",
    "#                                         label_smoothing = 1e-2,\n",
    "#                                         learning_rate = 1e-3,\n",
    "#                                         epochs=2#2000\n",
    "#                                     )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
