{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of this notebook:\n",
    "1. Explain Notebook\n",
    "2. Serve as stepping stone to allow function to be reproduced across TS Pred Domains\n",
    "\n",
    "### Competition Explanation\n",
    "1. Leaderboard score: 6476\n",
    "2. Notebook Score: 9766, which served as baseline and building block to notebook of score: 11,480\n",
    "3. Notebook Credit: https://www.kaggle.com/code/tarlannazarov/own-jane-street-with-keras-nn/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0-dev20210806\n",
      "2.6.0\n",
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "# Print Tensorflow, Keras, Numpy version to make version clear to prevent dependecy issues\n",
    "import tensorflow\n",
    "import keras\n",
    "import numpy \n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import choices\n",
    "\n",
    "\n",
    "SEED = 1111\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# train = pd.read_csv('../input/jane-street-market-prediction/train.csv')\n",
    "# train = pd.read_csv('../input/synthetic-jane-street-dataset/train.csv',engine='python')\n",
    "train_orig = pd.read_csv('./Jane Street Data/Splitted_Data/JaneStreet_Part0.csv')\n",
    "train_orig\n",
    "train = train_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26362</td>\n",
       "      <td>6</td>\n",
       "      <td>1.758028</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.003567</td>\n",
       "      <td>-0.002244</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641876</td>\n",
       "      <td>0.795410</td>\n",
       "      <td>0.337828</td>\n",
       "      <td>1.292695</td>\n",
       "      <td>6.078467</td>\n",
       "      <td>-2.141768</td>\n",
       "      <td>-3.630178</td>\n",
       "      <td>4.806393</td>\n",
       "      <td>1181473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26363</td>\n",
       "      <td>6</td>\n",
       "      <td>2.880795</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.862270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.814259</td>\n",
       "      <td>2.306749</td>\n",
       "      <td>4.012111</td>\n",
       "      <td>0.043977</td>\n",
       "      <td>-2.754400</td>\n",
       "      <td>-2.217010</td>\n",
       "      <td>-1.578796</td>\n",
       "      <td>0.741731</td>\n",
       "      <td>1273349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26364</td>\n",
       "      <td>6</td>\n",
       "      <td>9.118387</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>0.026842</td>\n",
       "      <td>0.053148</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>...</td>\n",
       "      <td>5.145386</td>\n",
       "      <td>-0.311186</td>\n",
       "      <td>0.262822</td>\n",
       "      <td>2.664963</td>\n",
       "      <td>1.783466</td>\n",
       "      <td>-0.820957</td>\n",
       "      <td>1.262784</td>\n",
       "      <td>-0.615489</td>\n",
       "      <td>2238809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26365</td>\n",
       "      <td>6</td>\n",
       "      <td>10.575239</td>\n",
       "      <td>-0.007252</td>\n",
       "      <td>-0.013773</td>\n",
       "      <td>-0.033410</td>\n",
       "      <td>-0.048703</td>\n",
       "      <td>-0.040168</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.217926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399924</td>\n",
       "      <td>1.578563</td>\n",
       "      <td>-0.193868</td>\n",
       "      <td>-1.338982</td>\n",
       "      <td>2.696016</td>\n",
       "      <td>-3.583999</td>\n",
       "      <td>2.477546</td>\n",
       "      <td>-0.361818</td>\n",
       "      <td>2189869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26367</td>\n",
       "      <td>6</td>\n",
       "      <td>3.907241</td>\n",
       "      <td>-0.033508</td>\n",
       "      <td>-0.056233</td>\n",
       "      <td>-0.078685</td>\n",
       "      <td>-0.082471</td>\n",
       "      <td>-0.086419</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.418044</td>\n",
       "      <td>...</td>\n",
       "      <td>1.355057</td>\n",
       "      <td>1.659399</td>\n",
       "      <td>0.554493</td>\n",
       "      <td>0.424183</td>\n",
       "      <td>-1.588647</td>\n",
       "      <td>1.661917</td>\n",
       "      <td>-1.742249</td>\n",
       "      <td>0.360720</td>\n",
       "      <td>1011153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168254</th>\n",
       "      <td>194616</td>\n",
       "      <td>41</td>\n",
       "      <td>0.127290</td>\n",
       "      <td>-0.002901</td>\n",
       "      <td>-0.004369</td>\n",
       "      <td>-0.015155</td>\n",
       "      <td>-0.026200</td>\n",
       "      <td>-0.019054</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895137</td>\n",
       "      <td>...</td>\n",
       "      <td>1.453422</td>\n",
       "      <td>1.772596</td>\n",
       "      <td>-0.060673</td>\n",
       "      <td>5.001509</td>\n",
       "      <td>-0.784987</td>\n",
       "      <td>1.476904</td>\n",
       "      <td>0.847102</td>\n",
       "      <td>-1.697419</td>\n",
       "      <td>1787297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168255</th>\n",
       "      <td>194617</td>\n",
       "      <td>41</td>\n",
       "      <td>9.499657</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>-0.003893</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654635</td>\n",
       "      <td>-3.354002</td>\n",
       "      <td>-1.561084</td>\n",
       "      <td>-0.021235</td>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.578562</td>\n",
       "      <td>2.351930</td>\n",
       "      <td>-1.043938</td>\n",
       "      <td>2245831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168256</th>\n",
       "      <td>194618</td>\n",
       "      <td>41</td>\n",
       "      <td>0.880071</td>\n",
       "      <td>-0.009220</td>\n",
       "      <td>-0.010878</td>\n",
       "      <td>-0.016373</td>\n",
       "      <td>-0.005701</td>\n",
       "      <td>-0.004407</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.033749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.441910</td>\n",
       "      <td>2.025904</td>\n",
       "      <td>1.111816</td>\n",
       "      <td>-0.007807</td>\n",
       "      <td>-0.383317</td>\n",
       "      <td>-0.112840</td>\n",
       "      <td>-0.702947</td>\n",
       "      <td>-0.997980</td>\n",
       "      <td>1805522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168258</th>\n",
       "      <td>194620</td>\n",
       "      <td>41</td>\n",
       "      <td>0.078104</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>1</td>\n",
       "      <td>2.024954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218148</td>\n",
       "      <td>0.648862</td>\n",
       "      <td>-1.365715</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>0.601280</td>\n",
       "      <td>3.224246</td>\n",
       "      <td>-0.650631</td>\n",
       "      <td>-1.370604</td>\n",
       "      <td>887604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168259</th>\n",
       "      <td>194621</td>\n",
       "      <td>41</td>\n",
       "      <td>1.821867</td>\n",
       "      <td>-0.001364</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.003310</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1</td>\n",
       "      <td>4.862565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153567</td>\n",
       "      <td>-2.253743</td>\n",
       "      <td>1.257677</td>\n",
       "      <td>-0.393732</td>\n",
       "      <td>-1.254929</td>\n",
       "      <td>-1.516557</td>\n",
       "      <td>-0.194138</td>\n",
       "      <td>5.912747</td>\n",
       "      <td>1444418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139638 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  date     weight    resp_1    resp_2    resp_3    resp_4  \\\n",
       "0            26362     6   1.758028  0.000596 -0.000543 -0.003567 -0.002244   \n",
       "1            26363     6   2.880795  0.000708  0.000629  0.002001  0.001216   \n",
       "2            26364     6   9.118387  0.024360  0.028085  0.026842  0.053148   \n",
       "3            26365     6  10.575239 -0.007252 -0.013773 -0.033410 -0.048703   \n",
       "5            26367     6   3.907241 -0.033508 -0.056233 -0.078685 -0.082471   \n",
       "...            ...   ...        ...       ...       ...       ...       ...   \n",
       "168254      194616    41   0.127290 -0.002901 -0.004369 -0.015155 -0.026200   \n",
       "168255      194617    41   9.499657 -0.000010 -0.000433 -0.002241 -0.003893   \n",
       "168256      194618    41   0.880071 -0.009220 -0.010878 -0.016373 -0.005701   \n",
       "168258      194620    41   0.078104 -0.001270 -0.001045  0.006422  0.016154   \n",
       "168259      194621    41   1.821867 -0.001364 -0.000164 -0.003310 -0.000708   \n",
       "\n",
       "            resp  feature_0  feature_1  ...  feature_122  feature_123  \\\n",
       "0       0.000164          1  -3.172026  ...     0.641876     0.795410   \n",
       "1       0.000674         -1  -1.862270  ...    -0.814259     2.306749   \n",
       "2       0.079602          1   0.285112  ...     5.145386    -0.311186   \n",
       "3      -0.040168         -1   0.217926  ...    -0.399924     1.578563   \n",
       "5      -0.086419         -1   1.418044  ...     1.355057     1.659399   \n",
       "...          ...        ...        ...  ...          ...          ...   \n",
       "168254 -0.019054          1   0.895137  ...     1.453422     1.772596   \n",
       "168255 -0.000241         -1   2.338139  ...     1.654635    -3.354002   \n",
       "168256 -0.004407         -1   3.033749  ...    -0.441910     2.025904   \n",
       "168258  0.010319          1   2.024954  ...     0.218148     0.648862   \n",
       "168259  0.000053          1   4.862565  ...     0.153567    -2.253743   \n",
       "\n",
       "        feature_124  feature_125  feature_126  feature_127  feature_128  \\\n",
       "0          0.337828     1.292695     6.078467    -2.141768    -3.630178   \n",
       "1          4.012111     0.043977    -2.754400    -2.217010    -1.578796   \n",
       "2          0.262822     2.664963     1.783466    -0.820957     1.262784   \n",
       "3         -0.193868    -1.338982     2.696016    -3.583999     2.477546   \n",
       "5          0.554493     0.424183    -1.588647     1.661917    -1.742249   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "168254    -0.060673     5.001509    -0.784987     1.476904     0.847102   \n",
       "168255    -1.561084    -0.021235     0.304516     0.578562     2.351930   \n",
       "168256     1.111816    -0.007807    -0.383317    -0.112840    -0.702947   \n",
       "168258    -1.365715     0.255495     0.601280     3.224246    -0.650631   \n",
       "168259     1.257677    -0.393732    -1.254929    -1.516557    -0.194138   \n",
       "\n",
       "        feature_129    ts_id  action  \n",
       "0          4.806393  1181473       1  \n",
       "1          0.741731  1273349       1  \n",
       "2         -0.615489  2238809       1  \n",
       "3         -0.361818  2189869       0  \n",
       "5          0.360720  1011153       0  \n",
       "...             ...      ...     ...  \n",
       "168254    -1.697419  1787297       0  \n",
       "168255    -1.043938  2245831       0  \n",
       "168256    -0.997980  1805522       0  \n",
       "168258    -1.370604   887604       1  \n",
       "168259     5.912747  1444418       1  \n",
       "\n",
       "[139638 rows x 140 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 3s 82ms/step - loss: 0.7391 - AUC: 0.5003\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.7134 - AUC: 0.5020\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.7052 - AUC: 0.5044\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.7010 - AUC: 0.5043\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.6983 - AUC: 0.5037\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.6966 - AUC: 0.5049\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.6956 - AUC: 0.5058\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.6948 - AUC: 0.5070\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.6942 - AUC: 0.5082\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.6940 - AUC: 0.5086\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = train.query('date > 5').reset_index(drop = True) \n",
    "train\n",
    "train = train[train['weight'] != 0]\n",
    "\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "\n",
    "train['action'] = ((train['resp'].values) > 0).astype(int)\n",
    "\n",
    "\n",
    "features = [c for c in train.columns if \"feature\" in c]\n",
    "\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "\n",
    "X_train = train.loc[:, train.columns.str.contains('feature')]\n",
    "#y_train = (train.loc[:, 'action'])\n",
    "\n",
    "y_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_mlp(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "batch_size = 5000\n",
    "hidden_units = [150, 150, 150]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "clf = create_mlp(\n",
    "    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )\n",
    "\n",
    "clf.fit(X_train, y_train, epochs=10, batch_size=5000)\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(clf)\n",
    "\n",
    "th = 0.5000\n",
    "\n",
    "\n",
    "# f = np.median\n",
    "# models = models[-3:]\n",
    "# import janestreet\n",
    "# env = janestreet.make_env()\n",
    "# for (test_df, pred_df) in tqdm(env.iter_test()):\n",
    "#     if test_df['weight'].item() > 0:\n",
    "#         x_tt = test_df.loc[:, features].values\n",
    "#         if np.isnan(x_tt[:, 1:].sum()):\n",
    "#             x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "#         pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n",
    "#         pred = f(pred)\n",
    "#         pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n",
    "#     else:\n",
    "#         pred_df.action = 0\n",
    "#     env.predict(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
